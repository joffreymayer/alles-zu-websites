[["index.html", "My Knowledge Database for Websites Chapter 1 Set-Up 1.1 Backend: Git &amp; Github 1.2 Create a Bookdown-Website", " My Knowledge Database for Websites Joffrey Anthony 2021-11-08 Chapter 1 Set-Up 1.1 Backend: Git &amp; Github Create a Github-Account. We also need to download Git, a Version-Control System, because you can track all your changes and it is easier to collaborate on Code-Projects. Next, we need to link our Github-Account to Git. To do this, use the Terminal and type in the following two commands: 3.1) git config --global user.name \"YOUR GIBHUB USERNAME HERE\" 3.2) git config --global user.email \"your_github_email@example.com\" Create a Public &amp; Private SSH-Key in order to not always type in your password. Follow the instruction of this Youtube-Tutorial (ab 2:40-4:03). In order to be able to use the SSH-Key, you need to follow my instruction in the Video on my local computer, situated on the following path: /Users/jomaye/Nextcloud/Dokumente/Life/Video Tutorials/Github/ssh-key-zum-laufen-bringen.mov. If the Git code that I provided in the video does not work, then I recommend you to also try this code out: git remote set-url --add --push origin git@github.com:yourGithubUsername/yourRepo.git 1.2 Create a Bookdown-Website Use this Bookdown-Template to create an awesome website like this one, you are currently at right now. Follow all the instruction of this 5 Minutes Youtube-Video. "],["seo.html", "Chapter 2 SEO 2.1 PDFs", " Chapter 2 SEO Für die Webseiten-Indexierung innerhalb der Google-Suchmaschine ist es von grösster Bedeutung, dass du die Kunst des Seo (Search Engine Optimization) beherrschts. 2.1 PDFs Ein PDF wird von Google grundsätzlich automatisch in die Suchmaschine aufgenommen. Oftmals verwendest du PDFs jedoch als Ergänzungen zu den Type in the following into you .htaccess-File, for Appache-Servers: &lt;Files ~ &quot;\\.pdf$&quot;&gt; Header set X-Robots-Tag &quot;noindex, nofollow&quot; &lt;/Files&gt; If you have NGINX, you need this code instead: location ~* \\.pdf$ { add_header X-Robots-Tag &quot;noindex, nofollow&quot;; } To check if it worked, you need to view the HTTP Header of your PDF. You can do this via the developer tools in the Google Chrome Browser (by hitting F12). Developer-Tools For a more precise explanation, I recommend this site. This is the output you should see being printed If the solution above does not work, I have found an alternative way: &lt;FilesMatch &quot;.pdf$&quot;&gt; Header set X-Robots-Tag &quot;noindex, nofollow&quot; &lt;/FilesMatch&gt; Quelle: (Google Developers, Teil 1)[https://developers.google.com/search/docs/advanced/robots/robots_meta_tag] How can I prevent my PDF files from appearing in search results; or if they already do, how can I remove them? The simplest way to prevent PDF documents from appearing in search results is to add an X-Robots-Tag: noindex in the HTTP header used to serve the file. If they’re already indexed, they’ll drop out over time if you use the X-Robot-Tag with the noindex directive. For faster removals, you can use the URL removal tool in Google Webmaster Tools. Quelle: Google-Developers, Teil 2 "],["a-caucus-race-and-a-long-tale.html", "Chapter 3 A caucus-race and a long tale", " Chapter 3 A caucus-race and a long tale "]]
